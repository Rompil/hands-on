{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uh9u3iTqMHwb",
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GPEwPym-MPIR",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Практическое введение в PySpark для Data Scientists\n",
    "\n",
    "---\n",
    "\n",
    "by Roman Pilyugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GSTuYdTMu6z",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Содержание\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1. [Немного теории. RDD, Transformation, Action](#theory)\n",
    "2. [Если я уже умею в Python и Pandas](#forSkilledPeople)\n",
    "3. [Сравнение операций Pandas и PySpark](#PandasVsPySpark)\n",
    "    1. [Чтение данных](#csvRead)\n",
    "    3. [Некоторые основные примеры манипуляций с данными](#moreOps)\n",
    "    4. [Визуализация данным](#pics)\n",
    "    5. [Сохранение данных](#storeData)\n",
    "4. [Погружаемся в Machine Learning](#ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5q570MiAPyyL",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Немного теории. RDD, Transformation, Action <a name =theory></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kv2hjQnmAFh8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**RDD** (Resilient Distributed Dataset) - Это фундаментальная абстракция структуры данных в Spark. Ее можно представить в виде неизменяемой коллекции объектов. Сама коллекция может быть размещена по нескольким нодам (отдельным машинам) для параллельной обработки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-Vz9DqLJEr3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Transformation** - операция, результатом которой является новый RDD. Таким образром, transformation задает связь ( последовательность) между RDD в виде последовательности преобразований. \n",
    "\n",
    "*Надо отметить, что все операции Transformation выполняются в **Lazy mode**, т.е. пока не вызвать одну из оперций Action, то преобразования не выполняются.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5xZXgYPaVYB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Основные операции Transformation\n",
    "\n",
    "* map(function) — *применяет функцию function к каждому элементу датасета*\n",
    "\n",
    "* .filter(function) — *возвращает все элементы датасета, на которых функция function вернула истинное значение*\n",
    "\n",
    "* .distinct([numTasks]) — *возвращает датасет, который содержит уникальные элементы исходного датасета*\n",
    "\n",
    "**Также стоит отметить об операциях над множествами, смысл которых понятен из названий:**\n",
    "\n",
    "* .union(otherDataset)\n",
    "\n",
    "* .intersection(otherDataset)\n",
    "\n",
    "* .cartesian(otherDataset) — *новый датасет содержит в себе всевозможные пары (A,B), где первый элемент принадлежит исходному датасету, а второй — датасету-аргументу*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_qqNHh9JKFQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Action** - операции, результат которых появляется немедленно, в отличии от Transformation. Это могут быть операции для вывода результата вычислений, сохранения в отдельный файл или выгрузка во внешнее хранилище.\n",
    "*Можно сказать, что Action операция опзволяет извлечь данные из RDD.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZCBrN6kJGHW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Основные операции Action\n",
    "\n",
    "\n",
    "* .saveAsTextFile(path) — *сохраняет данные в текстовый файл (в hdfs, на локальную машину или в любую другую поддерживаемую файловую систему — полный список можно посмотреть в документации)*\n",
    "\n",
    "* .collect() — *возвращает элементы датасета в виде массива. Как правило, это применяется в случаях, когда данных в датасете уже мало (применены различные фильтры и преобразования) — и необходима визуализация, либо дополнительный анализ данных, например средствами пакета Pandas*\n",
    "\n",
    "* .take(n) — *возвращает в виде массива первые n элементов датасета*\n",
    "\n",
    "* .count() — *возвращает количество элементов в датасете*\n",
    "\n",
    "* .reduce(function) — *знакомая операция для тех, кто знаком с MapReduce. Из механизма этой операции следует, что функция function (которая принимает на вход 2 аргумента возвращает одно значение) должна быть обязательно коммутативной и ассоциативной*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaYz4jUbQVYE",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Если я уже умею в Python и Pandas <a name=forSkilledPeople></a>\n",
    "\n",
    "<p>Для практикующего специалиста по анализу данных PySpark может быть полезен когда: </p>\n",
    "\n",
    "\n",
    "*   Уже знакомы c Python (Scala, Java, R) и Pandas DataFrame\n",
    "*   Есть возможность развернуть кластер для обработки данных\n",
    "*   Нужно обрабатывать больше объемы данных [^1].\n",
    "\n",
    "[^1]:   Под большими данными понимаются те, что не помещаются в оперативной памяти одного компьютера\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-M22qEyZQsef",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сравнение операций Pandas и PySpark <a name=PandasVsPySpark></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Чтение данных<a name=csvRead></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6tCfVQ29LCS",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Как это в Pandas__\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/FileStore/tables/gt_sales_by_pos_month.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__В PySpark__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UW-l3wk5_S5q",
    "scrolled": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.options(header=True)\\\n",
    "                .options(inferSchema=True)\\\n",
    "                .csv('/FileStore/tables/gt_sales_by_pos_month.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Манипуляции с данными <a name=manipulation></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Взглянем на результат предыдущей операции\n",
    "__Как это в Pandas__\n",
    "```python\n",
    "df\n",
    "df.head(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__В PySpark__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.show()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "в остально все похоже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.columns # узнаем про колонки в таблице\n",
    "df.dtypes # узнаем про типы данных в такблице"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Операции с колонками\n",
    "\n",
    "__В Pandas__\n",
    "```python\n",
    "df.drop('pmsm_pos_code', axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__В PySpark__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.drop('pmsm_pos_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "В PySpark нет понятия индекса и axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Фильтрация__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[df.meg_mrsp > 85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[(df.meg_mrsp > 85)&(df.brand_variant=='JADE LA ROSE 100 SSL')]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "PySpark_hands_on.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
