{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark_hands_on.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "uh9u3iTqMHwb",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GPEwPym-MPIR"
      },
      "cell_type": "markdown",
      "source": [
        "# Практическое введение в PySpark для Data Scientists\n",
        "\n",
        "---\n",
        "\n",
        "by Roman Pilyugin"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3GSTuYdTMu6z"
      },
      "cell_type": "markdown",
      "source": [
        "## Содержание\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. [Немного теории. RDD, Transformation, Action](#theory)\n",
        "2. [Если я уже умею в Python и Pandas](#forSkilledPeople)\n",
        "3. [Сравнение операций Pandas и PySpark](#PandasVsPySpark)\n",
        "    1. [Чтение данных](#csvRead)\n",
        "    3. [Некоторые основные примеры манипуляций с данными](#moreOps)\n",
        "    4. [Визуализация данным](#pics)\n",
        "    5. [Сохранение данных](#storeData)\n",
        "4. [Погружаемся в Machine Learning](#ML)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5q570MiAPyyL"
      },
      "cell_type": "markdown",
      "source": [
        "##  Немного теории. RDD, Transformation, Action <a name =theory></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Kv2hjQnmAFh8"
      },
      "cell_type": "markdown",
      "source": [
        "**RDD** (Resilient Distributed Dataset) - Это фундаментальная абстракция структуры данных в Spark. Ее можно представить в виде неизменяемой коллекции объектов. Сама коллекция может быть размещена по нескольким нодам (отдельным машинам) для параллельной обработки."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "D-Vz9DqLJEr3"
      },
      "cell_type": "markdown",
      "source": [
        "**Transformation** - операция, результатом которой является новый RDD. Таким образром, transformation задает связь ( последовательность) между RDD в виде последовательности преобразований. \n",
        "\n",
        "*Надо отметить, что все операции Transformation выполняются в **Lazy mode**, т.е. пока не вызвать одну из оперций Action, то преобразования не выполняются.*"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "C5xZXgYPaVYB"
      },
      "cell_type": "markdown",
      "source": [
        "### Основные операции Transformation\n",
        "\n",
        "* map(function) — *применяет функцию function к каждому элементу датасета*\n",
        "\n",
        "* .filter(function) — *возвращает все элементы датасета, на которых функция function вернула истинное значение*\n",
        "\n",
        "* .distinct([numTasks]) — *возвращает датасет, который содержит уникальные элементы исходного датасета*\n",
        "\n",
        "**Также стоит отметить об операциях над множествами, смысл которых понятен из названий:**\n",
        "\n",
        "* .union(otherDataset)\n",
        "\n",
        "* .intersection(otherDataset)\n",
        "\n",
        "* .cartesian(otherDataset) — *новый датасет содержит в себе всевозможные пары (A,B), где первый элемент принадлежит исходному датасету, а второй — датасету-аргументу*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7_qqNHh9JKFQ"
      },
      "cell_type": "markdown",
      "source": [
        "**Action** - операции, результат которых появляется немедленно, в отличии от Transformation. Это могут быть операции для вывода результата вычислений, сохранения в отдельный файл или выгрузка во внешнее хранилище.\n",
        "*Можно сказать, что Action операция опзволяет извлечь данные из RDD.*"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OZCBrN6kJGHW"
      },
      "cell_type": "markdown",
      "source": [
        "### Основные операции Action\n",
        "\n",
        "\n",
        "* .saveAsTextFile(path) — *сохраняет данные в текстовый файл (в hdfs, на локальную машину или в любую другую поддерживаемую файловую систему — полный список можно посмотреть в документации)*\n",
        "\n",
        "* .collect() — *возвращает элементы датасета в виде массива. Как правило, это применяется в случаях, когда данных в датасете уже мало (применены различные фильтры и преобразования) — и необходима визуализация, либо дополнительный анализ данных, например средствами пакета Pandas*\n",
        "\n",
        "* .take(n) — *возвращает в виде массива первые n элементов датасета*\n",
        "\n",
        "* .count() — *возвращает количество элементов в датасете*\n",
        "\n",
        "* .reduce(function) — *знакомая операция для тех, кто знаком с MapReduce. Из механизма этой операции следует, что функция function (которая принимает на вход 2 аргумента возвращает одно значение) должна быть обязательно коммутативной и ассоциативной*\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gaYz4jUbQVYE"
      },
      "cell_type": "markdown",
      "source": [
        "## Если я уже умею в Python и Pandas <a name=forSkilledPeople></a>\n",
        "\n",
        "<p>Для практикующего специалиста по анализу данных PySpark может быть полезен когда: </p>\n",
        "\n",
        "\n",
        "*   Уже знакомы c Python (Scala, Java, R) и Pandas DataFrame\n",
        "*   Есть возможность развернуть кластер для обработки данных\n",
        "*   Нужно обрабатывать больше объемы данных [^1].\n",
        "\n",
        "[^1]:   Под большими данными понимаются те, что не помещаются в оперативной памяти одного компьютера\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-M22qEyZQsef"
      },
      "cell_type": "markdown",
      "source": [
        "## Сравнение операций Pandas и PySpark <a name=PandasVsPySpark></a>"
      ]
    },
    {
      "metadata": {
        "id": "mdyIB0vRYa0X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Чтение данных<a name=csvRead></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "a6tCfVQ29LCS"
      },
      "cell_type": "markdown",
      "source": [
        "__Как это в Pandas__\n",
        "```python\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/FileStore/tables/gt_sales_by_pos_month.csv')\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "8PZ_5y-CYa0b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__В PySpark__"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UW-l3wk5_S5q",
        "scrolled": false,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = spark.read.options(header=True)\\\n",
        "                .options(inferSchema=True)\\\n",
        "                .csv('/FileStore/tables/gt_sales_by_pos_month.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBqLWndgYa0i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Манипуляции с данными <a name=manipulation></a>"
      ]
    },
    {
      "metadata": {
        "id": "422_EVeRYa0k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Взглянем на результат предыдущей операции\n",
        "__Как это в Pandas__\n",
        "```python\n",
        "df\n",
        "df.head(5)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "NerFtCZoYa0m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__В PySpark__"
      ]
    },
    {
      "metadata": {
        "id": "I_oHGU6_Ya0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.show()\n",
        "df.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gv-jTF7SYa0r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "в остально все похоже:"
      ]
    },
    {
      "metadata": {
        "id": "EhYQPRtBYa0s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.columns # узнаем про колонки в таблице\n",
        "df.dtypes # узнаем про типы данных в такблице"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxTyHTbLYa0u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Операции с колонками\n",
        "\n",
        "__В Pandas__\n",
        "```python\n",
        "df.drop('pmsm_pos_code', axis=1)\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "DivMx1TEYa0v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__В PySpark__"
      ]
    },
    {
      "metadata": {
        "id": "cEDFrUgEYa0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.drop('pmsm_pos_code')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ArKVZgOOYa0y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "В PySpark нет понятия индекса и axis"
      ]
    },
    {
      "metadata": {
        "id": "mpUMZq78Ya0z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Фильтрация__"
      ]
    },
    {
      "metadata": {
        "id": "Fo2Q9TdaYa00",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[df.meg_mrsp > 85]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZAFKsGrPYa03",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[(df.meg_mrsp > 85)&(df.brand_variant=='JADE LA ROSE 100 SSL')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eekcNOSVYlqo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}